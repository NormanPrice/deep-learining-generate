{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H1xUwO0WoO_",
        "outputId": "69858b45-1df1-4c8f-901f-4899a4b9362d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.23.5)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56438 sha256=bfa17c287b0c03d39daed82a7d43b834b2655ed1e5128ae8c8a275f32bc7f13c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n"
          ]
        }
      ],
      "source": [
        "!pip install np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "43JHR1T2WLL3",
        "outputId": "37292046-d6b4-4c18-d354-1931d791ba80"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3cfcfa57137b>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambdaCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'np_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from keras.layers import Dense, LSTM, Input, Embedding, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import LambdaCallback\n",
        "import np_utils\n",
        "from keras.models import load_model, save_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oFFbJC8WOrF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "load_saved_model = True\n",
        "train_model = False\n",
        "\n",
        "# Load in the text and perform some cleanup\n",
        "seq_length = 20\n",
        "filename = \"/Users/norbert/Desktop/LSTM/data/rockyou-75.txt\"\n",
        "\n",
        "with open(filename, encoding='utf-8-sig') as f:\n",
        "    text = f.read().strip()\n",
        "\n",
        "# Convert text to characters\n",
        "chars = sorted(list(set(text)))\n",
        "total_chars = len(chars)\n",
        "print(total_chars)\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "\n",
        "\n",
        "# Vectorization\n",
        "X = np.zeros((len(text) - seq_length, seq_length, total_chars), dtype=bool)\n",
        "y = np.zeros((len(text) - seq_length, total_chars), dtype=bool)\n",
        "for i in range(len(text) - seq_length):\n",
        "    for t, char in enumerate(text[i:i + seq_length]):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[text[i + seq_length]]] = 1\n",
        "\n",
        "if load_saved_model:\n",
        "    model = load_model('/Users/norbert/Desktop/LSTM/models/model-saveLSTM-91-chars.h5')\n",
        "else:\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, input_shape=(seq_length, total_chars), return_sequences=True))  # Adjusted input shape\n",
        "    model.add(LSTM(512, return_sequences=True))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(total_chars, activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.00001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def generate_text(length, diversity):\n",
        "    start_index = np.random.randint(0, len(text) - seq_length - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + seq_length]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_pred = np.zeros((1, seq_length, total_chars))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "        sentence = sentence[1:] + next_char\n",
        "        generated += next_char\n",
        "    return generated\n",
        "\n",
        "if train_model:\n",
        "    history = model.fit(X, y, batch_size=32, epochs=100)\n",
        "    model.save('/Users/norbert/Desktop/LSTM/models/model-saving-LSTM-91-chars.h5')\n",
        "    # Plot training loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.title('Model Loss Over Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(generate_text(200, 0.55))\n",
        "with open('LSTM-output.txt', 'w') as file:\n",
        "    # Write the generated text to the file\n",
        "    file.write(generate_text(1000, 0.5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KrHDl76WREb"
      },
      "outputs": [],
      "source": [
        "#Tutaj mozna chyba zaczac jezeli jest zaladowany model i chcemy \"personalizowac\"\n",
        "def vectorize_text(text, seq_length, total_chars, char_indices):\n",
        "    X = np.zeros((len(text) - seq_length, seq_length, total_chars), dtype=bool)\n",
        "    y = np.zeros((len(text) - seq_length, total_chars), dtype=bool)\n",
        "    for i in range(len(text) - seq_length):\n",
        "        for t, char in enumerate(text[i:i + seq_length]):\n",
        "            X[i, t, char_indices[char]] = 1\n",
        "        y[i, char_indices[text[i + seq_length]]] = 1\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZwx_AmCWSdO"
      },
      "outputs": [],
      "source": [
        "def read_words_from_file(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        words = [line.strip() for line in f if line.strip()]\n",
        "    return words\n",
        "\n",
        "\n",
        "def fine_tune_on_words(model, words, char_indices, indices_char, seq_length, total_chars, epochs=5):\n",
        "    fine_tune_text = ' '.join(words)\n",
        "    X_fine, y_fine = vectorize_text(fine_tune_text, seq_length, total_chars, char_indices)\n",
        "    history = model.fit(X, y, batch_size=32, epochs=30)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU0B5egYWTpB"
      },
      "outputs": [],
      "source": [
        "personalized_words = ['Brena', 'Brenda', 'Brenn', 'Brenna', 'Brett', 'Bria', 'Briana', 'Brianna', 'Brianne', 'Bride', 'Bridget', 'Bridgette', 'Bridie', 'Brier', 'Brietta', 'Brigid', 'Brigida', 'Brigit', 'Brigitta', 'Brigitte', 'Brina', 'Briney', 'Brinn', 'Brinna', 'Briny', 'Brit', 'Brita', 'Britney', 'Britni', 'Britt', 'Britta', 'Brittan', 'Brittaney', 'Brittani', 'Brittany', 'Britte', 'Britteny', 'Brittne', 'Brittney', 'Brittni', 'Brook', 'Brooke', 'Brooks', 'Brunhilda', 'Brunhilde', 'Bryana', 'Bryn', 'Bryna', 'Brynn', 'Brynna', 'Brynne', 'Buffy', 'Bunni', 'Bunnie', 'Bunny', 'Cacilia', 'Cacilie', 'Cahra', 'Cairistiona', 'Caitlin', 'Caitrin', 'Cal', 'Calida', 'Calla', 'Calley', 'Calli', 'Callida', 'Callie', 'Cally', 'Calypso', 'Cam', 'Camala', 'Camel', 'Camella', 'Camellia', 'Cami', 'Camila', 'Camile', 'Camilla', 'Camille', 'Cammi', 'Cammie', 'Cammy', 'Candace', 'Candi', 'Candice', 'Candida', 'Candide', 'Candie', 'Candis', 'Candra', 'Candy', 'Caprice', 'Cara', 'Caralie', 'Caren', 'Carena', 'Caresa', 'Caressa', 'Caresse', 'Carey', 'Cari', 'Caria', 'Carie', 'Caril', 'Carilyn', 'Carin', 'Carina', 'Carine', 'Cariotta', 'Carissa', 'Carita', 'Caritta', 'Carla', 'Carlee', 'Carleen', 'Carlen', 'Carlene', 'Carley', 'Carlie', 'Carlin', 'Carlina', 'Carline', 'Carlita', 'Carlota', 'Carlotta', 'Carly', 'Carlye', 'Carlyn', 'Carlynn', 'Carlynne', 'Carma', 'Carmel', 'Carmela', 'Carmelia', 'Carmelina', 'Carmelita', 'Carmella', 'Carmelle', 'Carmen', 'Carmencita', 'Carmina', 'Carmine', 'Carmita', 'Carmon', 'Caro', 'Carol', 'Carol-Jean', 'Carola', 'Carolan', 'Carolann', 'Carole', 'Carolee', 'Carolin', 'Carolina', 'Caroline', 'Caroljean', 'Carolyn', 'Carolyne', 'Carolynn', 'Caron', 'Carree', 'Carri', 'Carrie', 'Carrissa', 'Carroll', 'Carry', 'Cary', 'Caryl', 'Caryn', 'Casandra', 'Casey', 'Casi', 'Casie', 'Cass', 'Cassandra', 'Cassandre', 'Cassandry', 'Cassaundra', 'Cassey', 'Cassi', 'Cassie', 'Cassondra', 'Cassy', 'Catarina', 'Cate', 'Caterina', 'Catha', 'Catharina', 'Catharine', 'Cathe', 'Cathee', 'Catherin', 'Catherina', 'Catherine', 'Cathi', 'Cathie', 'Cathleen', 'Cathlene', 'Cathrin', 'Cathrine', 'Cathryn', 'Cathy', 'Cathyleen', 'Cati', 'Catie', 'Catina', 'Catlaina', 'Catlee', 'Catlin', 'Catrina', 'Catriona', 'Caty', 'Caye', 'Cayla', 'Cecelia', 'Cecil', 'Cecile', 'Ceciley', 'Cecilia', 'Cecilla', 'Cecily', 'Ceil', 'Cele', 'Celene', 'Celesta', 'Celeste', 'Celestia', 'Celestina', 'Celestine', 'Celestyn', 'Celestyna', 'Celia', 'Celie', 'Celina', 'Celinda', 'Celine', 'Celinka', 'Celisse', 'Celka', 'Celle', 'Cesya', 'Chad', 'Chanda', 'Chandal', 'Chandra', 'Channa', 'Chantal', 'Chantalle', 'Charil', 'Charin', 'Charis', 'Charissa', 'Charisse', 'Charita', 'Charity', 'Charla', 'Charlean', 'Charleen', 'Charlena', 'Charlene', 'Charline', 'Charlot', 'Charlotta', 'Charlotte', 'Charmain', 'Charmaine', 'Charmane', 'Charmian', 'Charmine', 'Charmion', 'Charo', 'Charyl', 'Chastity', 'Chelsae', 'Chelsea', 'Chelsey', 'Chelsie', 'Chelsy', 'Cher', 'Chere', 'Cherey', 'Cheri', 'Cherianne', 'Cherice', 'Cherida', 'Cherie', 'Cherilyn', 'Cherilynn', 'Cherin', 'Cherise', 'Cherish', 'Cherlyn', 'Cherri', 'Cherrita', 'Cherry', 'Chery', 'Cherye', 'Cheryl', 'Cheslie', 'Chiarra', 'Chickie', 'Chicky', 'Chiquia', 'Chiquita', 'Chlo', 'Chloe', 'Chloette', 'Chloris', 'Chris', 'Chrissie', 'Chrissy', 'Christa', 'Christabel', 'Christabella', 'Christal', 'Christalle', 'Christan', 'Christean', 'Christel', 'Christen', 'Christi', 'Christian', 'Christiana', 'Christiane', 'Christie', 'Christin', 'Christina', 'Christine', 'Christy', 'Christye', 'Christyna', 'Chrysa', 'Chrysler', 'Chrystal', 'Chryste', 'Chrystel', 'Cicely', 'Cicily', 'Ciel', 'Cilka', 'Cinda', 'Cindee', 'Cindelyn', 'Cinderella', 'Cindi', 'Cindie', 'Cindra', 'Cindy', 'Cinnamon', 'Cissiee', 'Cissy', 'Clair', 'Claire', 'Clara', 'Clarabelle', 'Clare', 'Claresta', 'Clareta', 'Claretta', 'Clarette', 'Clarey', 'Clari', 'Claribel', 'Clarice', 'Clarie', 'Clarinda', 'Clarine', 'Clarissa', 'Clarisse', 'Clarita', 'Clary', 'Claude', 'Claudelle', 'Claudetta', 'Claudette', 'Claudia', 'Claudie', 'Claudina', 'Claudine', 'Clea', 'Clem', 'Clemence', 'Clementia', 'Clementina', 'Clementine', 'Clemmie', 'Clemmy', 'Cleo', 'Cleopatra', 'Clerissa', 'Clio', 'Clo', 'Cloe', 'Cloris', 'Clotilda', 'Clovis', 'Codee', 'Codi', 'Codie', 'Cody', 'Coleen', 'Colene', 'Coletta', 'Colette', 'Colleen', 'Collen', 'Collete', 'Collette', 'Collie', 'Colline', 'Colly', 'Con', 'Concettina', 'Conchita', 'Concordia', 'Conni', 'Connie', 'Conny', 'Consolata', 'Constance', 'Constancia', 'Constancy', 'Constanta', 'Constantia', 'Constantina', 'Constantine', 'Consuela', 'Consuelo', 'Cookie', 'Cora', 'Corabel', 'Corabella', 'Corabelle', 'Coral', 'Coralie', 'Coraline', 'Coralyn', 'Cordelia', 'Cordelie', 'Cordey', 'Cordi', 'Cordie', 'Cordula', 'Cordy', 'Coreen', 'Corella', 'Corenda', 'Corene', 'Coretta', 'Corette', 'Corey', 'Cori', 'Corie', 'Corilla', 'Corina', 'Corine', 'Corinna', 'Corinne', 'Coriss', 'Corissa', 'Corliss', 'Corly', 'Cornela', 'Cornelia', 'Cornelle', 'Cornie', 'Corny', 'Correna', 'Correy', 'Corri', 'Corrianne', 'Corrie', 'Corrina', 'Corrine', 'Corrinne', 'Corry', 'Cortney', 'Cory', 'Cosetta', 'Cosette', 'Costanza', 'Courtenay', 'Courtnay', 'Courtney', 'Crin', 'Cris', 'Crissie', 'Crissy', 'Crista', 'Cristabel', 'Cristal', 'Cristen', 'Cristi', 'Cristie', 'Cristin', 'Cristina', 'Cristine', 'Cristionna', 'Cristy', 'Crysta', 'Crystal', 'Crystie', 'Cthrine', 'Cyb', 'Cybil', 'Cybill', 'Cymbre', 'Cynde', 'Cyndi', 'Cyndia', 'Cyndie', 'Cyndy', 'Cynthea', 'Cynthia', 'Cynthie', 'Cynthy', 'Dacey', 'Dacia']\n",
        "model = load_model('/content/model-saveLSTM-91-chars.h5')\n",
        "optimizer = Adam(learning_rate=0.00001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "#model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.00001), loss='your_loss_function')\n",
        "history = fine_tune_on_words(model, personalized_words, char_indices, indices_char, seq_length, total_chars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPzOSFm8WVWe"
      },
      "outputs": [],
      "source": [
        "\n",
        "generated_text = generate_text(1000, 0.5)\n",
        "with open('LSTM-output-fine-tuning.txt', 'w') as file:\n",
        "    file.write(generated_text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
